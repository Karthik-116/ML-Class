{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We-5YNWSUWb6",
        "outputId": "47cee7b5-dbd0-4f53-b118-149ec0360504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=7b33867cc20b40af6201c47267c1cc901b59b4ff74ce9297e5186b59e0724649\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "from lime.explanation import Explanation # Used for type hinting\n",
        "\n",
        "#  A1. Stacking Classifier Implementation\n",
        "#base_models a list of base learners (like decision tree,svm,knn)\n",
        "#fianl estimator is meta model that learns the predictions of the base model\n",
        "def create_stacking_classifier(base_models: list, final_estimator_choice) -> StackingClassifier:\n",
        "    #stackingclassifier is an esemble method\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=base_models,\n",
        "        final_estimator=final_estimator_choice,\n",
        "        cv=5,  #using 5 fold cross validation for base models\n",
        "        n_jobs=-1 #this tells scikit learn to use all available cores for parallel learning\n",
        "    )\n",
        "    return stacking_clf\n",
        "\n",
        "# A2. Pipeline Implementation\n",
        "\n",
        "def create_and_train_pipeline(classifier_model: StackingClassifier, X_train: pd.DataFrame, y_train: np.ndarray) -> Pipeline:\n",
        "    #x_train is your training features\n",
        "    #y_train is your training labels\n",
        "    pipeline_steps = [\n",
        "        ('scaler', StandardScaler()),#applying standardization\n",
        "        ('stacking_clf', classifier_model)\n",
        "    ]\n",
        "    model_pipeline = Pipeline(steps=pipeline_steps)#pipeline ensures first it does scalling then passes the data into the classifier\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "    return model_pipeline\n",
        "\n",
        "#  A3. LIME Explainer Implementation (RECTIFIED: Added top_labels)\n",
        "\n",
        "def explain_pipeline_prediction_lime(\n",
        "    trained_pipeline: Pipeline,\n",
        "    X_train: pd.DataFrame,#training feature matrix\n",
        "    X_test_sample: np.ndarray,#a simgle sample(row) from the test set\n",
        "    feature_names: list,#feature names\n",
        "    class_names: list,#name of the classes\n",
        ") -> Explanation:\n",
        "\n",
        "    # Create the LIME Tabular Explainer.\n",
        "    explainer = LimeTabularExplainer(#builds a local surrogate model(usallly linear regression)\n",
        "        training_data=X_train.values,\n",
        "        feature_names=feature_names,\n",
        "        class_names=class_names,\n",
        "        mode='classification',#tells LIME that this is a classification problem(not regression)\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    # Function to returns class probabilities for each batch from pipeline\n",
        "    predict_fn = lambda x: trained_pipeline.predict_proba(x)\n",
        "\n",
        "    # Generate the explanation for the chosen test sample\n",
        "    explanation = explainer.explain_instance(\n",
        "        data_row=X_test_sample,\n",
        "        predict_fn=predict_fn,#the probability function defined above\n",
        "        num_features=10, #shoes the top 10 important features for prediction\n",
        "        # Forces LIME to generate explanations for all classes\n",
        "        top_labels=len(class_names)\n",
        "    )\n",
        "\n",
        "    return explanation\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # loading  the dataset\n",
        "    FILE_NAME = \"/content/features_filtered.csv\"\n",
        "\n",
        "    try:\n",
        "        # attempts to load the dataset into a pandad DataFrame\n",
        "        df = pd.read_csv(FILE_NAME)\n",
        "    except FileNotFoundError:\n",
        "        df = pd.read_csv(f\"/content/{FILE_NAME}\")\n",
        "\n",
        "    # remove the not useful features for classification\n",
        "    X = df.drop(columns=['file', 'run', 'onset_s', 'label'])\n",
        "    y_raw = df['label'] #the target label column\n",
        "\n",
        "\n",
        "    X_cleaned = X.apply(pd.to_numeric, errors='coerce')#coerce is used if the value is invalid it will be replaced with NaN\n",
        "    valid_indices = X_cleaned.dropna().index\n",
        "    X = X_cleaned.loc[valid_indices]\n",
        "    y_raw = y_raw.loc[valid_indices]\n",
        "\n",
        "\n",
        "    # Encode the categorical target variable to integers\n",
        "    label_encoder = LabelEncoder() #convert categorical into numerical(integer labels)\n",
        "    y = label_encoder.fit_transform(y_raw)\n",
        "    class_names = label_encoder.classes_.tolist()\n",
        "\n",
        "    #extract the names of all features\n",
        "    feature_names = X.columns.tolist()\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    ) #startify ensures the class distribution is preserved\n",
        "\n",
        "    print(\"Data Preparation Complete \")\n",
        "    print(f\"Total Samples (after cleaning): {len(X)}\")\n",
        "    print(f\"Number of Features: {X.shape[1]}\")\n",
        "    print(f\"Classes: {class_names}\\n\")\n",
        "\n",
        "    # defining Base Models and Final Estimator (A1)\n",
        "    base_classifiers = [\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "        ('nb', GaussianNB())\n",
        "    ]\n",
        "    # NOTE: multi_class='multinomial' is the correct setting for multi-class logistic regression\n",
        "    meta_model = LogisticRegression(solver='saga', max_iter=2000, multi_class='multinomial', random_state=42, n_jobs=-1)\n",
        "#logistic regression is used as meta model for stacking because it can learns weights for combining base predictions\n",
        "    #  Calling Stacking Classifier (A1)\n",
        "    stacking_model = create_stacking_classifier(base_classifiers, meta_model)\n",
        "\n",
        "    # reate and Train Pipeline (A2)\n",
        "    full_pipeline = create_and_train_pipeline(stacking_model, X_train, y_train) #it builds a pipeline\n",
        "\n",
        "    # Evaluating the pipeline on test data\n",
        "    y_pred = full_pipeline.predict(X_test)\n",
        "    pipeline_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Pipeline Training and Evaluation (A2)\")\n",
        "    print(f\"Test Set Accuracy: {pipeline_accuracy:.4f}\\n\")\n",
        "\n",
        "    # explain Pipeline Prediction using LIME (A3)\n",
        "    sample_to_explain_idx = 10 #selects a single test sample\n",
        "    X_explain_sample = X_test.iloc[sample_to_explain_idx].values #extracting feature value\n",
        "    y_true_label = class_names[y_test[sample_to_explain_idx]]\n",
        "\n",
        "    # creating a LIME Tabular Explainer\n",
        "    lime_explanation = explain_pipeline_prediction_lime(\n",
        "        full_pipeline, X_train, X_explain_sample, feature_names, class_names\n",
        "    )\n",
        "\n",
        "    # Get the predicted class and explaining predictions for chosen test sample\n",
        "    prediction_proba = full_pipeline.predict_proba(X_explain_sample.reshape(1, -1))[0]#gives probabilities\n",
        "    predicted_class_idx = np.argmax(prediction_proba)#finding top probabilities\n",
        "    predicted_label = class_names[predicted_class_idx]#maps the index back to original name\n",
        "    predicted_probability = prediction_proba[predicted_class_idx] #probability score for the predicted class.\n",
        "\n",
        "    print(\"LIME Explanation for Pipeline Outcome (A3)\")\n",
        "    print(f\"Explaining Sample Index: {sample_to_explain_idx}\")\n",
        "    print(f\"True Label: {y_true_label}, Predicted Label: {predicted_label}\")\n",
        "    print(f\"Predicted Probability for '{predicted_label}': {predicted_probability:.4f}\\n\")\n",
        "\n",
        "\n",
        "    idx_to_explain = predicted_class_idx\n",
        "    label_to_explain = predicted_label\n",
        "\n",
        "    print(f\"Top 10 Features Contributing to Prediction: '{label_to_explain}' (index {idx_to_explain})\")\n",
        "\n",
        "\n",
        "    # lime returns a list of feature,weights\n",
        "    try:\n",
        "        for feature, weight in lime_explanation.as_list(label=idx_to_explain):\n",
        "            print(f\"  {feature}: {weight:+.4f}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"ERROR: Failed to retrieve explanation for index {idx_to_explain} due to LIME internal error: {e}\")\n",
        "        available_labels = lime_explanation.available_labels()\n",
        "        if available_labels:\n",
        "            # Fallback to display the top available explanation if the predicted one is missing\n",
        "            fallback_idx = available_labels[0]\n",
        "            fallback_label = class_names[fallback_idx]\n",
        "            print(f\"Displaying explanation for top available class: '{fallback_label}' (index {fallback_idx})\")\n",
        "            for feature, weight in lime_explanation.as_list(label=fallback_idx):\n",
        "                 print(f\"  {feature}: {weight:+.4f}\")\n",
        "        else:\n",
        "            print(\"No explanation available for any class.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deCc6rZSYiXB",
        "outputId": "dc5418fc-9177-4172-83f8-fa88ad0ca1df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preparation Complete \n",
            "Total Samples (after cleaning): 39347\n",
            "Number of Features: 256\n",
            "Classes: ['both_feet', 'both_fists', 'left', 'rest', 'right']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Pipeline Training and Evaluation (A2) ---\n",
            "Test Set Accuracy: 0.5413\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LIME Explanation for Pipeline Outcome (A3) ---\n",
            "Explaining Sample Index: 10\n",
            "True Label: both_fists, Predicted Label: both_feet\n",
            "Predicted Probability for 'both_feet': 0.4446\n",
            "\n",
            "Top 10 Features Contributing to Prediction: 'both_feet' (index 0)\n",
            "  O2..__theta > 0.00: +0.0090\n",
            "  0.00 < Fpz.__beta <= 0.00: +0.0074\n",
            "  Cp1.__delta > 0.00: +0.0072\n",
            "  Tp7.__theta > 0.00: +0.0067\n",
            "  Pz..__delta > 0.00: +0.0067\n",
            "  Fc4.__theta > 0.00: +0.0065\n",
            "  0.00 < Po4.__beta <= 0.00: +0.0061\n",
            "  T10.__theta > 0.00: +0.0057\n",
            "  0.00 < Afz.__alpha <= 0.00: -0.0057\n",
            "  P3..__delta > 0.00: +0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}